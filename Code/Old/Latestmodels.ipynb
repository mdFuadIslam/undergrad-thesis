{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOtKTbENeINTSVTrYsqfFd2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install ultralytics\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q1yeDYzH6mAZ","executionInfo":{"status":"ok","timestamp":1705338189393,"user_tz":-360,"elapsed":7009,"user":{"displayName":"Kaushik Roy","userId":"10427999406034653061"}},"outputId":"86c3e39f-97b6-4ed5-b249-1ddef8868c65"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.1.1-py3-none-any.whl (699 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m699.8/699.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop>=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n","Collecting hub-sdk>=0.0.2 (from ultralytics)\n","  Downloading hub_sdk-0.0.3-py3-none-any.whl (37 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: hub-sdk, thop, ultralytics\n","Successfully installed hub-sdk-0.0.3 thop-0.1.1.post2209072238 ultralytics-8.1.1\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"C_4vBU67lTWP","executionInfo":{"status":"ok","timestamp":1705340271675,"user_tz":-360,"elapsed":1320080,"user":{"displayName":"Kaushik Roy","userId":"10427999406034653061"}},"outputId":"dba2b01e-3743-45cf-d5e6-52ff611aadeb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.1 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=mnist, epochs=8, time=None, patience=50, batch=16, imgsz=32, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n","\n","Dataset not found ‚ö†Ô∏è, missing path /content/datasets/mnist, attempting download...\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/mnist.zip to '/content/datasets/mnist.zip'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.2M/28.2M [00:00<00:00, 283MB/s]\n","Unzipping /content/datasets/mnist.zip to /content/datasets/mnist...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70023/70023 [00:08<00:00, 8034.30file/s]\n"]},{"output_type":"stream","name":"stdout","text":["Dataset download success ‚úÖ (10.9s), saved to \u001b[1m/content/datasets/mnist\u001b[0m\n","\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/mnist/train... found 60000 images in 10 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m None...\n","\u001b[34m\u001b[1mtest:\u001b[0m /content/datasets/mnist/test... found 10000 images in 10 classes ‚úÖ \n","Overriding model.yaml nc=1000 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \n","YOLOv8n-cls summary: 99 layers, 1451098 parameters, 1451098 gradients, 3.4 GFLOPs\n","Transferred 156/158 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/mnist/train... 60000 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60000/60000 [00:07<00:00, 7817.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/mnist/train.cache\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/mnist/test... 10000 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:01<00:00, 7425.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/mnist/test.cache\n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n","WARNING ‚ö†Ô∏è TensorBoard graph visualization failure Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])\n","8 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/8     0.495G      2.707         16         32:   0%|          | 17/3750 [00:01<03:40, 16.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["        1/8     0.495G      2.736         16         32:   1%|          | 44/3750 [00:03<02:46, 22.23it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 45.4MB/s]\n","        1/8     0.495G      1.352         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [02:50<00:00, 22.02it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:05<00:00, 57.86it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.934      0.998\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        2/8     0.363G     0.6577         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [02:35<00:00, 24.06it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:06<00:00, 47.13it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.961      0.999\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        3/8     0.363G     0.5228         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [02:28<00:00, 25.18it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:06<00:00, 47.71it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.973      0.999\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        4/8     0.363G     0.4459         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [02:29<00:00, 25.16it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:06<00:00, 47.04it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.978          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        5/8     0.363G     0.3841         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [02:28<00:00, 25.27it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:06<00:00, 46.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.978          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        6/8     0.363G     0.3337         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [02:29<00:00, 25.07it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:06<00:00, 46.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.982          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        7/8     0.363G     0.2992         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [02:29<00:00, 25.08it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:06<00:00, 46.69it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.984          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        8/8     0.363G     0.2666         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [02:28<00:00, 25.32it/s]\n","               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:06<00:00, 47.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      0.985          1\n","\n","8 epochs completed in 0.354 hours.\n","Optimizer stripped from runs/classify/train/weights/last.pt, 3.0MB\n","Optimizer stripped from runs/classify/train/weights/best.pt, 3.0MB\n","\n","Validating runs/classify/train/weights/best.pt...\n","Ultralytics YOLOv8.1.1 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","YOLOv8n-cls summary (fused): 73 layers, 1447690 parameters, 0 gradients, 3.3 GFLOPs\n","WARNING ‚ö†Ô∏è Dataset 'split=val' not found, using 'split=test' instead.\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/mnist/train... found 60000 images in 10 classes ‚úÖ \n","\u001b[34m\u001b[1mval:\u001b[0m None...\n","\u001b[34m\u001b[1mtest:\u001b[0m /content/datasets/mnist/test... found 10000 images in 10 classes ‚úÖ \n"]},{"output_type":"stream","name":"stderr","text":["               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:05<00:00, 61.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      0.985          1\n","Speed: 0.0ms preprocess, 0.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/train\u001b[0m\n","Results saved to \u001b[1mruns/classify/train\u001b[0m\n","Ultralytics YOLOv8.1.1 üöÄ Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.00GHz)\n","YOLOv8n-cls summary (fused): 73 layers, 1447690 parameters, 0 gradients, 3.3 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/classify/train/weights/best.pt' with input shape (1, 3, 32, 32) BCHW and output shape(s) (1, 10) (2.8 MB)\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n","Collecting onnx>=1.12.0\n","  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 15.7/15.7 MB 55.3 MB/s eta 0:00:00\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.23.5)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.15.0\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 8.4s, installed 1 package: ['onnx>=1.12.0']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 8.6s, saved as 'runs/classify/train/weights/best.onnx' (5.5 MB)\n","\n","Export complete (10.0s)\n","Results saved to \u001b[1m/content/runs/classify/train/weights\u001b[0m\n","Predict:         yolo predict task=classify model=runs/classify/train/weights/best.onnx imgsz=32  \n","Validate:        yolo val task=classify model=runs/classify/train/weights/best.onnx imgsz=32 data=mnist  \n","Visualize:       https://netron.app\n"]},{"output_type":"execute_result","data":{"text/plain":["'runs/classify/train/weights/best.onnx'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}],"source":["from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO('yolov8n-cls.pt')  # load a pretrained model (recommended for training)\n","\n","# Train the model\n","results = model.train(data='mnist', epochs=8, imgsz=32,plots=True,batch=16)\n","\n","model.export(format='onnx')\n"]},{"cell_type":"code","source":["model.export(format='onnx',imgsz=(28,28))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"G5WpVLKuRfFv","executionInfo":{"status":"ok","timestamp":1705341637284,"user_tz":-360,"elapsed":1629,"user":{"displayName":"Kaushik Roy","userId":"10427999406034653061"}},"outputId":"02b5804f-c87e-445a-9013-8933be17e5a1"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.1 üöÄ Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.00GHz)\n","YOLOv8n-cls summary (fused): 73 layers, 1447690 parameters, 0 gradients, 3.3 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/classify/train/weights/best.pt' with input shape (1, 3, 28, 28) BCHW and output shape(s) (1, 10) (2.8 MB)\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.2s, saved as 'runs/classify/train/weights/best.onnx' (5.5 MB)\n","\n","Export complete (1.4s)\n","Results saved to \u001b[1m/content/runs/classify/train/weights\u001b[0m\n","Predict:         yolo predict task=classify model=runs/classify/train/weights/best.onnx imgsz=28  \n","Validate:        yolo val task=classify model=runs/classify/train/weights/best.onnx imgsz=28 data=mnist  \n","Visualize:       https://netron.app\n"]},{"output_type":"execute_result","data":{"text/plain":["'runs/classify/train/weights/best.onnx'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","model = YOLO('/content/runs/classify/train/weights/best.pt')\n","results = model('/content/test.jpg')\n","\n","for result in results:\n","    boxes = result.boxes  # Boxes object for bbox outputs\n","    masks = result.masks  # Masks object for segmentation masks outputs\n","    keypoints = result.keypoints  # Keypoints object for pose outputs\n","    probs = result.probs  # Probs object for classification outputs\n","    print(probs.top1)\n","    print(probs.top5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1rIfLcUmFC1F","executionInfo":{"status":"ok","timestamp":1705342034959,"user_tz":-360,"elapsed":552,"user":{"displayName":"Kaushik Roy","userId":"10427999406034653061"}},"outputId":"bd9db60f-cdc1-4298-896f-48086f95d2fd"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/test.jpg: 32x32 1 0.80, 2 0.10, 7 0.03, 4 0.02, 8 0.01, 7.2ms\n","Speed: 1.4ms preprocess, 7.2ms inference, 0.1ms postprocess per image at shape (1, 3, 32, 32)\n","1\n","[1, 2, 7, 4, 8]\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=predict model=/content/yolov8n-cls.pt conf=0.3 source=/content/digit_7.png save=True\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdTpLzCfZlfF","executionInfo":{"status":"ok","timestamp":1704118915777,"user_tz":-360,"elapsed":13999,"user":{"displayName":"Kaushik Roy","userId":"10427999406034653061"}},"outputId":"5eb3a98a-a775-4524-98ba-b1ab8ce2cd79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ‚ö†Ô∏è conflicting 'task=detect' passed with 'task=classify' model. Ignoring 'task=detect' and updating to 'task=classify' to match model.\n","Ultralytics YOLOv8.0.231 üöÄ Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n","YOLOv8n-cls summary (fused): 73 layers, 2715880 parameters, 0 gradients, 4.3 GFLOPs\n","\n","image 1/1 /content/digit_7.png: 224x224 loupe 0.43, bolo_tie 0.13, frying_pan 0.05, nematode 0.03, waffle_iron 0.02, 37.9ms\n","Speed: 2.0ms preprocess, 37.9ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n","Results saved to \u001b[1mruns/classify/predict\u001b[0m\n","üí° Learn more at https://docs.ultralytics.com/modes/predict\n"]}]},{"cell_type":"code","source":["!yolo export model=/content/best.pt format=saved_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyMZTJBfh-nI","executionInfo":{"status":"ok","timestamp":1704641278524,"user_tz":-360,"elapsed":73152,"user":{"displayName":"Kaushik Roy","userId":"10427999406034653061"}},"outputId":"c9e02af3-6fe9-4759-be2c-efaf261bba7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.236 üöÄ Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.00GHz)\n","YOLOv8n-cls summary (fused): 73 layers, 1447690 parameters, 0 gradients, 3.3 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/best.pt' with input shape (1, 3, 32, 32) BCHW and output shape(s) (1, 10) (2.8 MB)\n","2024-01-07 15:26:50.042272: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-07 15:26:50.042327: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-07 15:26:50.043875: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx', 'onnx2tf>=1.15.4,<=1.17.5', 'sng4onnx>=1.0.1', 'onnxsim>=0.4.33', 'onnx_graphsurgeon>=0.3.26', 'tflite_support', 'onnxruntime'] not found, attempting AutoUpdate...\n","Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Collecting onnx\n","  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 15.7/15.7 MB 216.2 MB/s eta 0:00:00\n","Collecting onnx2tf<=1.17.5,>=1.15.4\n","  Downloading onnx2tf-1.17.5-py3-none-any.whl (400 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 400.4/400.4 kB 344.3 MB/s eta 0:00:00\n","Collecting sng4onnx>=1.0.1\n","  Downloading sng4onnx-1.0.1-py3-none-any.whl (5.8 kB)\n","Collecting onnxsim>=0.4.33\n","  Downloading onnxsim-0.4.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2.2/2.2 MB 294.1 MB/s eta 0:00:00\n","Collecting onnx_graphsurgeon>=0.3.26\n","  Downloading https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl (42 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 42.1/42.1 kB 206.9 MB/s eta 0:00:00\n","Collecting tflite_support\n","  Downloading tflite_support-0.4.4-cp310-cp310-manylinux2014_x86_64.whl (60.8 MB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 60.8/60.8 MB 148.5 MB/s eta 0:00:00\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.4/6.4 MB 210.9 MB/s eta 0:00:00\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnxsim>=0.4.33) (13.7.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tflite_support) (1.4.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tflite_support) (23.5.26)\n","Collecting sounddevice>=0.4.4 (from tflite_support)\n","  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n","Collecting pybind11>=2.6.0 (from tflite_support)\n","  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 227.7/227.7 kB 361.3 MB/s eta 0:00:00\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 46.0/46.0 kB 195.8 MB/s eta 0:00:00\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->tflite_support) (1.16.0)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 86.8/86.8 kB 290.0 MB/s eta 0:00:00\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim>=0.4.33) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim>=0.4.33) (2.16.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite_support) (2.21)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim>=0.4.33) (0.1.2)\n","Installing collected packages: sng4onnx, pybind11, onnx2tf, onnx, humanfriendly, sounddevice, onnx_graphsurgeon, coloredlogs, tflite_support, onnxsim, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.15.0 onnx2tf-1.17.5 onnx_graphsurgeon-0.3.27 onnxruntime-1.16.3 onnxsim-0.4.35 pybind11-2.11.1 sng4onnx-1.0.1 sounddevice-0.4.6 tflite_support-0.4.4\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 53.0s, installed 7 packages: ['onnx', 'onnx2tf>=1.15.4,<=1.17.5', 'sng4onnx>=1.0.1', 'onnxsim>=0.4.33', 'onnx_graphsurgeon>=0.3.26', 'tflite_support', 'onnxruntime']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.15.0...\n","WARNING ‚ö†Ô∏è tensorflow<=2.13.1 is required, but tensorflow==2.15.0 is currently installed https://github.com/ultralytics/ultralytics/issues/5161\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n","100% 1.11M/1.11M [00:00<00:00, 125MB/s]\n","Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100% 1/1 [00:00<00:00, 48.50file/s]\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n","\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.35...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.6s, saved as '/content/best.onnx' (5.5 MB)\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m running 'onnx2tf -i \"/content/best.onnx\" -o \"/content/best_saved_model\" -nuo --non_verbose'\n","Summary on the non-converted ops:\n","---------------------------------\n"," * Accepted dialects: tfl, builtin, func\n"," * Non-Converted Ops: 62, Total Ops 168, % non-converted = 36.90 %\n"," * 62 ARITH ops\n","\n","- arith.constant:   62 occurrences  (f32: 54, i32: 8)\n","\n","\n","\n","  (f32: 6)\n","  (f32: 4)\n","  (f32: 26)\n","  (f32: 1)\n","  (f32: 26)\n","  (f32: 26)\n","  (f32: 5)\n","  (f32: 1)\n","  (f32: 8)\n","Summary on the non-converted ops:\n","---------------------------------\n"," * Accepted dialects: tfl, builtin, func\n"," * Non-Converted Ops: 62, Total Ops 222, % non-converted = 27.93 %\n"," * 62 ARITH ops\n","\n","- arith.constant:   62 occurrences  (f16: 54, i32: 8)\n","\n","\n","\n","  (f32: 6)\n","  (f32: 4)\n","  (f32: 26)\n","  (f32: 54)\n","  (f32: 1)\n","  (f32: 26)\n","  (f32: 26)\n","  (f32: 5)\n","  (f32: 1)\n","  (f32: 8)\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export failure ‚ùå 65.5s: generic_type: cannot initialize type \"StatusCode\": an object with that name is already defined\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 466, in entrypoint\n","    getattr(model, mode)(**overrides)  # default args from model\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 328, in export\n","    return Exporter(overrides=args, _callbacks=self.callbacks)(model=self.model)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/exporter.py\", line 263, in __call__\n","    f[5], keras_model = self.export_saved_model()\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/exporter.py\", line 122, in outer_func\n","    raise e\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/exporter.py\", line 117, in outer_func\n","    f, model = inner_func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/exporter.py\", line 724, in export_saved_model\n","    f.unlink() if 'quant_with_int16_act.tflite' in str(f) else self._add_tflite_metadata(file)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/exporter.py\", line 832, in _add_tflite_metadata\n","    from tflite_support import flatbuffers  # noqa\n","  File \"/usr/local/lib/python3.10/dist-packages/tflite_support/__init__.py\", line 53, in <module>\n","    from tflite_support import task\n","  File \"/usr/local/lib/python3.10/dist-packages/tflite_support/task/__init__.py\", line 32, in <module>\n","    from . import vision\n","  File \"/usr/local/lib/python3.10/dist-packages/tflite_support/task/vision/__init__.py\", line 20, in <module>\n","    from tensorflow_lite_support.python.task.vision import image_classifier\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_lite_support/python/task/vision/image_classifier.py\", line 23, in <module>\n","    from tensorflow_lite_support.python.task.vision.core import tensor_image\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_lite_support/python/task/vision/core/tensor_image.py\", line 19, in <module>\n","    from tensorflow_lite_support.python.task.vision.core.pybinds import image_utils\n","ImportError: generic_type: cannot initialize type \"StatusCode\": an object with that name is already defined\n"]}]}]}